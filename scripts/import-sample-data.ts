import {
  existsSync,
  lstatSync,
  readdirSync,
  readFileSync,
  writeFileSync,
} from 'fs';
import { createConnection } from 'mysql2/promise';
import { join } from 'path';

// Load env variables
require('dotenv').config();

interface Concept {
  id: string;
  label: string;
  definition: string;
  level: number;
  variants: string[];
}

interface Edge {
  parentId: string;
  childId: string;
}

const TRACKER_FILE = join(
  __dirname,
  '../docs/sample-data/from-wikidata/imported.txt',
);
const BASE_DATA_DIR = join(__dirname, '../docs/sample-data/from-wikidata');

async function main() {
  const args = process.argv.slice(2);
  const targetFolder = args[0]; // Optional specific folder

  const connection = await createConnection({
    host: process.env.DATABASE_HOST || 'localhost',
    port: parseInt(process.env.DATABASE_PORT || '3306'),
    user: process.env.DATABASE_USER || 'root',
    password: process.env.DATABASE_PASSWORD || 'rootpass123',
    database: process.env.DATABASE_NAME || 'dag_db',
    multipleStatements: true,
  });

  try {
    const importedFolders = existsSync(TRACKER_FILE)
      ? readFileSync(TRACKER_FILE, 'utf-8').split('\n').filter(Boolean)
      : [];

    let foldersToProcess: string[] = [];

    if (targetFolder) {
      foldersToProcess = [targetFolder];
    } else {
      foldersToProcess = readdirSync(BASE_DATA_DIR).filter((f) => {
        const fullPath = join(BASE_DATA_DIR, f);
        return (
          lstatSync(fullPath).isDirectory() && !importedFolders.includes(f)
        );
      });
    }

    if (foldersToProcess.length === 0) {
      console.log('‚ú® No new folders to import.');
      return;
    }

    console.log(`üìÇ Found ${foldersToProcess.length} folders to process:`);
    foldersToProcess.forEach((f) => console.log(`   - ${f}`));

    for (const folder of foldersToProcess) {
      try {
        const folderPath = join(BASE_DATA_DIR, folder);
        const conceptsPath = join(folderPath, 'concepts.json');
        const edgesPath = join(folderPath, 'edges.json');

        if (!existsSync(conceptsPath) || !existsSync(edgesPath)) {
          console.warn(
            `‚ö†Ô∏è Skipping ${folder}: concepts.json or edges.json missing.`,
          );
          continue;
        }

        console.log(`\nüì• Importing from: ${folder}...`);

        const concepts: Concept[] = JSON.parse(
          readFileSync(conceptsPath, 'utf-8'),
        );
        const edges: Edge[] = JSON.parse(readFileSync(edgesPath, 'utf-8'));

        console.log(
          `   Found ${concepts.length} concepts, ${edges.length} edges.`,
        );

        // --- 1. Database Import ---
        const now = new Date();
        const batchSize = 500;

        for (let i = 0; i < concepts.length; i += batchSize) {
          const batch = concepts.slice(i, i + batchSize);

          // Concepts
          const conceptValues = batch
            .map((c) => [
              c.id,
              c.label,
              c.definition || null,
              c.level,
              now,
              now,
            ])
            .flat();
          const conceptPlaceholders = batch
            .map(() => '(?, ?, ?, ?, ?, ?)')
            .join(',');
          await connection.execute(
            `INSERT IGNORE INTO concepts (id, label, definition, level, created_at, updated_at) VALUES ${conceptPlaceholders}`,
            conceptValues,
          );

          // Variants
          const variantValues: any[] = [];
          for (const c of batch) {
            if (c.variants?.length > 0) {
              for (const vName of c.variants) {
                variantValues.push(c.id, vName, now);
              }
            }
          }

          if (variantValues.length > 0) {
            const vBatchSize = 1000;
            for (let j = 0; j < variantValues.length; j += vBatchSize * 3) {
              const chunk = variantValues.slice(j, j + vBatchSize * 3);
              const placeholders = Array(chunk.length / 3)
                .fill('(?, ?, ?)')
                .join(',');
              await connection.execute(
                `INSERT IGNORE INTO variants (concept_id, name, created_at) VALUES ${placeholders}`,
                chunk,
              );
            }
          }
        }

        // Edges
        const edgeBatchSize = 1000;
        for (let i = 0; i < edges.length; i += edgeBatchSize) {
          const batch = edges.slice(i, i + edgeBatchSize);
          const values = batch.map((e) => [e.parentId, e.childId, now]).flat();
          const placeholders = batch.map(() => '(?, ?, ?)').join(',');
          await connection.execute(
            `INSERT IGNORE INTO edges (parent_id, child_id, created_at) VALUES ${placeholders}`,
            values,
          );
        }

        console.log(`‚úÖ Finished ${folder}.`);

        // Update tracker
        if (!targetFolder) {
          writeFileSync(TRACKER_FILE, folder + '\n', { flag: 'a' });
        }
      } catch (err) {
        console.error(
          `\n‚ùå Failed to import folder "${folder}":`,
          (err as Error).message,
        );
        console.log('‚è≠Ô∏è Skipping to next folder...');
      }
    }

    console.log('\nüåü All scheduled imports completed!');
  } catch (error) {
    console.error('\n‚ùå Global Import error:', error);
    process.exit(1);
  } finally {
    await connection.end();
  }
}

main();
